{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KnowTox_manuscript_SI\n",
    "This notebook is part of the supporting information to <br />\n",
    "\n",
    "<b> KnowTox: Pipeline and Case Study for Confident Prediction of Potential Toxic Effects of Compounds in Early Phases of Development </b><br />\n",
    "A. Morger<sup>1</sup>, M. Mathea<sup>2</sup>, J. H. Achenbach<sup>2</sup>, A. Wolf<sup>2</sup>, R. Buesen<sup>2</sup>, K-J. Schleifer<sup>2</sup>, R. Landsiedel<sup>2</sup>, A. Volkamer<sup>1</sup><br />\n",
    "<sup>1</sup>: <i>In Silico</i> Toxicology and Structural Bioinformatics, Charité Universitätsmedizin, Berlin, Germany, [volkamerlab.org](https://physiologie-ccm.charite.de/en/research_at_the_institute/volkamer_lab/) <br />\n",
    "<sup>2</sup>: BASF SE, Ludwigshafen, Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "In this notebook, we demonstrate how a conformal predictor is built, how the model is applied to make predictions for external data, and how to evaluate the internal (crossvalidation) and external predictions.\n",
    "\n",
    "The notebook consists of three main parts. \n",
    "\n",
    "1. Preparation: \n",
    "    - Used Python libraries are loaded\n",
    "    - Paths and parameters are defined \n",
    "2. Helper functions for \n",
    "    - Loading and formatting data\n",
    "    - Conformal predictor (CP) training on ToxCast data\n",
    "    - Conformal prediction on external data\n",
    "    - Evaluation of the predictions (internal crossvalidation and external data). \n",
    "3. Main script: \n",
    "    - Datasets are loaded\n",
    "    - Three CP models are built on ToxCast (original, normalised, normalised+balanced)\n",
    "    - Models are evaludated (internal and external)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "1. [Preparation](#preparation) <br>\n",
    "    1.1. [Import libraries and modules](#import-libraries-and-modules)<br>\n",
    "    1.2. [Define data paths](#define-data-paths)<br>\n",
    "    1.3. [Define parameters](#define-parameters)<br>\n",
    "2. [Define helper functions](#define-helper-functions)<br>\n",
    "    2.1. [Load and format data](#load-and-format)<br>\n",
    "    2.2. [Train conformal predictor on ToxCast dataset](#train-conformal-predictor)<br>\n",
    "    2.3. [Make conformal prediction for external dataset](#make-conformal-prediction)<br>\n",
    "    2.4. [Evaluate conformal predictors and predictions](#evaluate-conformal-predictors)<br>\n",
    "3. [Main script: apply helper functions to different model set-ups](#main-script)<br>\n",
    "    3.1. [Load ToxCast data to train conformal predictor](#load-toxcast-data)<br>\n",
    "    3.2. [Load external data to make conformal prediction](#load-external-data)<br>\n",
    "    3.3. [Train and make predictions with original, normalised and normalised+balanced model and evaluate](#train-and-make)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation <a name=\"preparation\"></a>\n",
    "### 1.1. Import libraries and modules <a name=\"import-libraries-and-modules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stdlib and 3rd party packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from nonconformist.icp import IcpClassifier\n",
    "from nonconformist.nc import InverseProbabilityErrFunc, NcFactory\n",
    "from nonconformist.acp import AggregatedCp, RandomSubSampler\n",
    "\n",
    "# Import own library\n",
    "from MyEqualSizeSampler import EqualSizeSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define data paths<a name=\"define-data-paths\"></a>\n",
    "The input files are provided as part of this Github repository. They contain preprocessed data as described in the manuscript (and briefly in the `README`). Original data were downloaded from [[1]](https://figshare.com/articles/ToxCast_and_Tox21_Data_Spreadsheet/6062503) (ToxCast dataset) and [[2]](https://www.tandfonline.com/doi/full/10.1080/1062936X.2016.1172665) (external data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "train_file = '../data/toxcast_CP_endpoints_MorganMACCS_mmpcReduced.csv'\n",
    "predict_file = '../data/external_AA_endpoint_MorganMACCS_mmpcReduced.csv'\n",
    "\n",
    "# Output files\n",
    "output_directory = '../data/output/'\n",
    "crossvalidation_output_file = f'{output_directory}crossvalidation'\n",
    "model_pickle_output_file = f'{output_directory}model'\n",
    "prediction_output_file = f'{output_directory}prediction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Define parameters <a name=\"define-parameters\"></a>\n",
    "The parameters are set as described in the Data and Methods section of the manuscript. \n",
    "- To ensure reproducibility, do not change the parameters. \n",
    "- However, they can be changed if you would like to adapt the notebook for your own purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input related\n",
    "endpoint_toxcast = '762' # Androgen receptor antagonism endpoint from ToxCast\n",
    "endpoint_external = 'AA' # Androgen receptor antagonism endpoint in external dataset\n",
    "\n",
    "fp_MorganMACCS = 'morgan_maccs' # Used to train original model\n",
    "fp_mmpcReduced = 'mm_pc_reduced' # Used to train normalised and normalised+balanced model\n",
    "\n",
    "# CP training related\n",
    "test_portion = 0.2 # Ratio to divide data into test and training set\n",
    "cal_portion = 0.3 # Ratio to divide training set into calibration and proper training set\n",
    "num_models = 5 # Number of ICPs trained per ACP # Change to 25 to follow manuscript methods. Calculation takes long.\n",
    "num_trees = 500 # Number of trees built in random forest\n",
    "\n",
    "icp_classifier_condition = (lambda instance: instance[1]) # Mondrian condition in conformal prediction\n",
    "aggregation_function = (lambda x: np.median(x,axis=2)) # Function to aggregate p-values in ACP\n",
    "error_function = InverseProbabilityErrFunc() # Nonconformity measure\n",
    "\n",
    "# Evaluation related\n",
    "cv = 5 # Number of folds in crossvalidation\n",
    "\n",
    "significance_level = 0.2 # Significance level used to evaluate conformal predictor/prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define helper functions <a name=\"define-helper-functions\"></a>\n",
    "### 2.1. Functions to load and format data <a name=\"load-and-format\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load and format molecules and descriptors from file\n",
    "def load_descriptor_dataframe(dataframe_file, cols, fingerprints):\n",
    "    \"\"\"\n",
    "    Read data from csv file \n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pd.read_csv(dataframe_file, usecols=cols)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "    # Reformat fingerprint information\n",
    "    for fp in fingerprints:\n",
    "        dataframe[fp] = dataframe[fp].apply(\n",
    "            lambda f: np.asarray([float(i) for i in f.replace('[', '').replace(']', '').split(',')]))\n",
    "    \n",
    "    # Reformat casn entry\n",
    "    if 'casn' in dataframe.columns:\n",
    "        dataframe['casn'].replace(',','_').tolist()\n",
    "    \n",
    "    print(dataframe.shape)\n",
    "    display(dataframe.head())\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate numpy arrays from dataframe column\n",
    "def format_to_numpy_array_for_ML(dataframe, column_name):\n",
    "    \"\"\"\n",
    "    Format data in column to numpy array for machine learning \n",
    "    \"\"\"\n",
    "    \n",
    "    column_list = dataframe[column_name].tolist()\n",
    "    np_array = np.asarray(column_list)\n",
    "    \n",
    "    return np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Function to train (and validate) conformal predictor on ToxCast dataset <a name=\"train-conformal-predictor\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to train conformal predictors on ToxCast dataset\n",
    "Within a (5-fold) crossvalidation, (five) ACPs are trained and saved as `acps_cv`. \n",
    "The predictions of the crossvalidation are written to `crossvalidation_output_file`.\n",
    "\n",
    "In this function, the model parameters are defined according to the insisted model setup:\n",
    "* Original model: No normaliser model, no equal size sampling\n",
    "* Normalised model: KNN Regressor normaliser model, no equal size sampling\n",
    "* Normalised+balanced model: KNN Regressor normaliser model, equal size sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_acp_cv(knowtox_model, data_X, class_y, casn, smiles, cv_folds, endpoint, fingerprint):\n",
    "    \"\"\"\n",
    "    Train ACP within a crossvalidation and save internal predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split data for crossvalidation\n",
    "    kf = StratifiedKFold(n_splits=cv_folds, random_state=42, shuffle=True,    )\n",
    "    acps_cv = [] # Save all ACPs to use for further prediction\n",
    "    \n",
    "    # Prepare output file\n",
    "    cv_outfile = open(f'{crossvalidation_output_file}_{endpoint}_{fingerprint}_{knowtox_model}.csv', 'w')\n",
    "    header = f'name,{endpoint},p0,p1,prediction,casn,smiles\\n'\n",
    "    cv_outfile.write(header)\n",
    "    \n",
    "    # Define parameters for choosen CP model set-up\n",
    "    if knowtox_model == 'original':\n",
    "        normaliser_model = None\n",
    "        acp_option = RandomSubSampler()\n",
    "    elif knowtox_model == 'normalised':\n",
    "        normaliser_model = KNeighborsRegressor()\n",
    "        acp_option = RandomSubSampler()\n",
    "    elif knowtox_model == 'normalised_balanced':\n",
    "        normaliser_model = KNeighborsRegressor()\n",
    "        acp_option = EqualSizeSampler()\n",
    "\n",
    "    print(knowtox_model, ' model:')\n",
    "    \n",
    "    # Fit model within crossvalidation and make prediction for respective test set\n",
    "    for train_index, test_index in kf.split(data_X, class_y):\n",
    "        \n",
    "        # Prepare the data splits\n",
    "        X_train, X_test = data_X[train_index], data_X[test_index]\n",
    "        y_train, y_test = class_y[train_index], class_y[test_index]\n",
    "        casn_train, casn_test = casn[train_index], casn[test_index]\n",
    "        smiles_train, smiles_test = smiles[train_index], smiles[test_index]\n",
    "        \n",
    "        # Create and train model on training set\n",
    "        forest = RandomForestClassifier(n_estimators=num_trees)\n",
    "        nc = NcFactory.create_nc(forest, err_func=error_function, normalizer_model=normaliser_model)\n",
    "        icp = IcpClassifier(nc, condition=icp_classifier_condition)\n",
    "        acp = AggregatedCp(n_models=num_models, predictor=icp, sampler=acp_option,\n",
    "                           aggregation_func=aggregation_function)\n",
    "        acp.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions for test set\n",
    "        predictions = acp.predict(X_test)\n",
    "        \n",
    "        # Write p-values and further compound information for each split into output file\n",
    "        long_line = ''\n",
    "        for n, i in enumerate(X_test):\n",
    "            newline = f'{n}, {y_test[n]}, {predictions[n][0]}, {predictions[n][1]}, {predictions[n]},'\\\n",
    "                        f'{casn_test[n].replace(\",\",\".\")}, {smiles_test[n]}\\n'\n",
    "            long_line += newline\n",
    "        cv_outfile.write(long_line)\n",
    "        \n",
    "        # Collect ACPs for later predictions of external test data\n",
    "        acps_cv.append(acp)\n",
    "    \n",
    "    cv_outfile.close()\n",
    "    \n",
    "    # Return trained ACP models\n",
    "    return acps_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Function to make conformal prediction for external dataset <a name=\"make-conformal-prediction\"></a>\n",
    "#### Define function to apply the model to a data set and to calculate p-values\n",
    "- First, pretrained ACP models (`acps`) are used to make predictions for an external dataset (`predict_df`). \n",
    "- Second, the predictions are saved in form of p-values for the active and inactive class, separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_acp_get_pvalues(acps, predict_df, chosen_fp, endpoint):\n",
    "    \"\"\"\n",
    "    Make conformal predictions for external test data and save p-values to dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    smiles_dict = {}\n",
    "    fingerprint_dict = {}\n",
    "    prediction_dict = {}\n",
    "    \n",
    "    # Store necessary data from data set in dictionaries\n",
    "    for idx, row in predict_df.iterrows():\n",
    "        smiles_dict[row['Name']] = row['smiles']\n",
    "        fingerprint_dict[row['Name']] = row[chosen_fp]\n",
    "    \n",
    "    # Make prediction for each entry (class-wise)\n",
    "    for tmp_entry, tmp_fp in fingerprint_dict.items():\n",
    "        predictions_p0 = np.array([])\n",
    "        predictions_p1 = np.array([])\n",
    "        \n",
    "        # With each of the ACPs trained in CV\n",
    "        for a in acps:\n",
    "            p = a.predict(np.array(tmp_fp, ndmin=2))\n",
    "            predictions_p0 = np.append(predictions_p0, p[0][0])\n",
    "            predictions_p1 = np.append(predictions_p1, p[0][1])\n",
    "        prediction_dict[(tmp_entry + '_p0')] = np.mean(predictions_p0)\n",
    "        prediction_dict[(tmp_entry + '_p1')] = np.mean(predictions_p1)\n",
    "    \n",
    "    # Calculate p-values per class\n",
    "    pvalues_class0 = []\n",
    "    pvalues_class1 = []\n",
    "\n",
    "    for i, r in predict_df.iterrows():\n",
    "        pvalues_class0.append(prediction_dict[r['Name'] + '_p0'])\n",
    "        pvalues_class1.append(prediction_dict[r['Name'] + '_p1'])  \n",
    "    \n",
    "    predict_df['p0'] = pvalues_class0\n",
    "    predict_df['p1'] = pvalues_class1\n",
    "    predict_df[chosen_fp] = predict_df[chosen_fp].apply(lambda fp: [i for i in fp])\n",
    "       \n",
    "    predict_df.to_csv(f'{prediction_output_file}_{endpoint}_{chosen_fp}_{knowtox_model}.csv')\n",
    "    \n",
    "    return predict_df, fingerprint_dict, prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Evaluate conformal predictors and predictions <a name=\"evaluate-conformal-predictors\"></a>\n",
    "#### Define evaluation functions to calculate validity, efficiency and accuracy\n",
    "Three functions are defined to evaluate the conformal predictions with respect to validity, efficiency and accuracy. Each function returns a dictionary containing three entries, _i.e._ the values for all compounds, the active compounds and the inactive compounds.\n",
    "##### 2.4.1 Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_set_sizes(df, ep):\n",
    "    \"\"\"\n",
    "    Calculate total number of compounds, class-wise and all compounds in data set\n",
    "    \"\"\"\n",
    "    \n",
    "    nof_neg = float(sum(df[ep].values == 0.0))\n",
    "    nof_pos = float(sum(df[ep].values == 1.0))\n",
    "    nof_all = float(nof_neg + nof_pos)\n",
    "    \n",
    "    return (nof_all, nof_neg, nof_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validity(dataframe, endpoint, significance):\n",
    "    \"\"\"\n",
    "    Calculate ratio of valid predictions, i.e. prediction sets containing the correct label\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate total number of compounds, class-wise and all compounds\n",
    "    total, total_0, total_1 = calculate_set_sizes(dataframe, endpoint)\n",
    "      \n",
    "    # Calculate number of wrongly predicted compounds \n",
    "    # (correct label not in prediction set at given significance level)\n",
    "    # class-wise\n",
    "    error_0 = sum((dataframe[endpoint].values == 0.0) & (dataframe.p0.values < significance))\n",
    "    error_1 = sum((dataframe[endpoint].values == 1.0) & (dataframe.p1.values < significance))\n",
    "\n",
    "    # Calculate error rate, class-wise and for all compounds\n",
    "    error_rate_0 = np.round(error_0 / total_0, 3)\n",
    "    error_rate_1 = np.round(error_1 / total_1, 3)\n",
    "    error_rate = np.round(((error_0 + error_1) / total), 3)\n",
    "    \n",
    "    return {'validity': (1 - error_rate), 'validity_1': (1 - error_rate_1), 'validity_0': (1 - error_rate_0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.2 Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nof_one_class_predictions(df, ep, label, significance):\n",
    "    \"\"\"\n",
    "    Calculate number of one class predictions for a specific class at a given significance level\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get number of comopounds that have respective label \n",
    "    # and only one of the p-values fullfills significance level\n",
    "    nof = sum((df[ep].values == label) \n",
    "               & (((df.p0.values < significance) & (df.p1.values >= significance)) \n",
    "                  | ((df.p0.values >= significance) & (df.p1.values < significance))))\n",
    "    \n",
    "    return nof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_efficiency(dataframe, endpoint, significance):\n",
    "    \"\"\"\n",
    "    Calculate ratio of efficient predictions, i.e. prediction sets containig one single label\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate total number of compounds, class-wise and all compounds\n",
    "    total, total_0, total_1 = calculate_set_sizes(dataframe, endpoint)\n",
    "    \n",
    "    # Calculate number of efficiently predicted compounds \n",
    "    # (only one label not in prediction set at given significance level)\n",
    "    # class-wise\n",
    "    efficiency_0 = calculate_nof_one_class_predictions(dataframe, endpoint, 0.0, significance)\n",
    "    efficiency_1 = calculate_nof_one_class_predictions(dataframe, endpoint, 1.0, significance)\n",
    "    \n",
    "    # Calculate efficiency rate, class-wise and for all compounds\n",
    "    efficiency_rate_0 = np.round(efficiency_0 / total_0, 3)\n",
    "    efficiency_rate_1 = np.round(efficiency_1 / total_1, 3)\n",
    "    efficiency_rate = np.round(((efficiency_0 + efficiency_1) / total), 3)\n",
    "    \n",
    "    return {'efficiency': efficiency_rate, 'efficiency_1': efficiency_rate_1, \n",
    "            'efficiency_0': efficiency_rate_0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(dataframe, endpoint, significance):\n",
    "    \"\"\"\n",
    "    Calculate ratio of accurate predictions, i.e. efficient prediction sets containing the one correct label\n",
    "    \"\"\"\n",
    "    # Calculate number of efficiently predicted compounds \n",
    "    # (only one label not in prediction set at given significance level)\n",
    "    # class-wise\n",
    "    efficiency_0 = calculate_nof_one_class_predictions(dataframe, endpoint, 0.0, significance)\n",
    "    efficiency_1 = calculate_nof_one_class_predictions(dataframe, endpoint, 1.0, significance)\n",
    "    efficiency = efficiency_0 + efficiency_1\n",
    "    \n",
    "    # Calculate number of correctly and efficiently predicted compounds \n",
    "    # (only one correct label in prediction set at given significance level)\n",
    "    # class-wise\n",
    "    accuracy_0 = sum((dataframe[endpoint].values == 0.0) & (dataframe.p0.values >= significance) &\n",
    "                     (dataframe.p1.values < significance))\n",
    "    accuracy_1 = sum((dataframe[endpoint].values == 1.0) & (dataframe.p0.values < significance) & \n",
    "                     (dataframe.p1.values >= significance))\n",
    "    \n",
    "    # Calculate accuracy rate, class-wise and for all compounds\n",
    "    accuracy_rate_0 = np.round(accuracy_0 / efficiency_0, 3)\n",
    "    accuracy_rate_1 = np.round(accuracy_1 / efficiency_1, 3)\n",
    "    accuracy_rate = np.round(((accuracy_0 + accuracy_1) / efficiency), 3)\n",
    "    \n",
    "    return {'accuracy': accuracy_rate, 'accuracy_1': accuracy_rate_1, 'accuracy_0': accuracy_rate_0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Main script: apply helper functions to different model set-ups <a name=\"main-script\"></a>\n",
    "\n",
    "The functions defined above are applied to the three model set-ups\n",
    "* Original model\n",
    "* Normalised model\n",
    "* Normalised+balanced model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load ToxCast data to train a conformal predictor <a name=\"load-toxcast-data\"></a>\n",
    "The ToxCast is loaded and formatted for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6713, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casn</th>\n",
       "      <th>762</th>\n",
       "      <th>smiles</th>\n",
       "      <th>morgan_maccs</th>\n",
       "      <th>mm_pc_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143-50-0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>O=C1C2(Cl)C3(Cl)C4(Cl)C(Cl)(Cl)C5(Cl)C3(Cl)C1(...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2385-85-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ClC1(Cl)C2(Cl)C3(Cl)C4(Cl)C(Cl)(Cl)C5(Cl)C3(Cl...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306-94-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FC1(F)C(F)(F)C(F)(F)C2(F)C(F)(F)C(F)(F)C(F)(F)...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86508-42-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FC(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105-06-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C=Cc1ccc(C=C)cc1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         casn  762                                             smiles  \\\n",
       "0    143-50-0  1.0  O=C1C2(Cl)C3(Cl)C4(Cl)C(Cl)(Cl)C5(Cl)C3(Cl)C1(...   \n",
       "1   2385-85-5  0.0  ClC1(Cl)C2(Cl)C3(Cl)C4(Cl)C(Cl)(Cl)C5(Cl)C3(Cl...   \n",
       "2    306-94-5  0.0  FC1(F)C(F)(F)C(F)(F)C2(F)C(F)(F)C(F)(F)C(F)(F)...   \n",
       "3  86508-42-1  0.0  FC(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F)(F)C(F...   \n",
       "4    105-06-6  0.0                                   C=Cc1ccc(C=C)cc1   \n",
       "\n",
       "                                        morgan_maccs  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                       mm_pc_reduced  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define input columns and fingerprints\n",
    "cols = [endpoint_toxcast, 'smiles', fp_MorganMACCS, fp_mmpcReduced, 'casn']\n",
    "fingerprints = [fp_MorganMACCS, fp_mmpcReduced]\n",
    "\n",
    "# Load dataframe\n",
    "train_dataframe = load_descriptor_dataframe(train_file, cols, fingerprints)\n",
    "\n",
    "# Generate numpy arrays as input for machine learning/conformal prediction\n",
    "X_MorganMACCS = format_to_numpy_array_for_ML(train_dataframe, fp_MorganMACCS)\n",
    "X_mmpcReduced = format_to_numpy_array_for_ML(train_dataframe, fp_mmpcReduced)\n",
    "toxcast_y = format_to_numpy_array_for_ML(train_dataframe, endpoint_toxcast)\n",
    "toxcast_casn = format_to_numpy_array_for_ML(train_dataframe, 'casn')\n",
    "toxcast_smiles = format_to_numpy_array_for_ML(train_dataframe, 'smiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Load external data to make conformal prediction <a name=\"load-external-data\"></a>\n",
    "The external data is loaded and formatted for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>smiles</th>\n",
       "      <th>AA</th>\n",
       "      <th>morgan_maccs</th>\n",
       "      <th>mm_pc_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1013056</td>\n",
       "      <td>CC(O)C1(O)CCC2C3CCC4=CC(=O)CCC4(C)C3CCC21C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1014521</td>\n",
       "      <td>CC(=O)c1ccc2ccc3cccc4ccc1c2c34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M10645</td>\n",
       "      <td>Oc1c(Cl)c(Cl)c(O)c(Cl)c1Cl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M10749</td>\n",
       "      <td>Clc1ccc(-c2cc(Cl)cc(Cl)c2)cc1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M11028</td>\n",
       "      <td>Clc1ccc(-c2ccccc2Cl)cc1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                      smiles   AA  \\\n",
       "0  M1013056  CC(O)C1(O)CCC2C3CCC4=CC(=O)CCC4(C)C3CCC21C  1.0   \n",
       "1  M1014521              CC(=O)c1ccc2ccc3cccc4ccc1c2c34  1.0   \n",
       "2    M10645                  Oc1c(Cl)c(Cl)c(O)c(Cl)c1Cl  1.0   \n",
       "3    M10749               Clc1ccc(-c2cc(Cl)cc(Cl)c2)cc1  1.0   \n",
       "4    M11028                     Clc1ccc(-c2ccccc2Cl)cc1  1.0   \n",
       "\n",
       "                                        morgan_maccs  \\\n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                       mm_pc_reduced  \n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define input columns and fingerprints\n",
    "cols=['Name', endpoint_external, 'smiles', fp_MorganMACCS, fp_mmpcReduced]\n",
    "fingerprints = [fp_MorganMACCS, fp_mmpcReduced]\n",
    "\n",
    "# Load dataframe\n",
    "external_df = load_descriptor_dataframe(predict_file, cols, fingerprints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Train and make predictions with original, normalised and normalised+balanced model and evaluate <a name=\"train-and-make\"></a>\n",
    "- Conformal predictors are fitted and evaluated on the internal test set\n",
    "- Predictions are made for the external data\n",
    "- The predictors/predictions are evaluated\n",
    "Three tables with the evaluation of the three models are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToxCast data: 6713.0 total, 5845.0 inactives, 868.0 actives\n",
      "\n",
      "External data: 361.0 total, 201.0 inactives, 160.0 actives\n",
      "\n",
      "original  model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validity</th>\n",
       "      <th>validity_1</th>\n",
       "      <th>validity_0</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_1</th>\n",
       "      <th>efficiency_0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxcast CV</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>external set</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              validity  validity_1  validity_0  efficiency  efficiency_1  \\\n",
       "toxcast CV       0.808       0.808       0.809       0.850         0.866   \n",
       "external set     0.781       0.812       0.756       0.731         0.712   \n",
       "\n",
       "              efficiency_0  accuracy  accuracy_1  accuracy_0  \n",
       "toxcast CV           0.848     0.775       0.778       0.774  \n",
       "external set         0.746     0.701       0.737       0.673  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalised  model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validity</th>\n",
       "      <th>validity_1</th>\n",
       "      <th>validity_0</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_1</th>\n",
       "      <th>efficiency_0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxcast CV</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>external set</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              validity  validity_1  validity_0  efficiency  efficiency_1  \\\n",
       "toxcast CV       0.844       0.835       0.845       0.362         0.149   \n",
       "external set     0.801       0.756       0.836       0.305         0.169   \n",
       "\n",
       "              efficiency_0  accuracy  accuracy_1  accuracy_0  \n",
       "toxcast CV           0.393     0.942       0.535       0.964  \n",
       "external set         0.413     0.782       0.556       0.855  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalised_balanced  model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validity</th>\n",
       "      <th>validity_1</th>\n",
       "      <th>validity_0</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_1</th>\n",
       "      <th>efficiency_0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxcast CV</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>external set</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              validity  validity_1  validity_0  efficiency  efficiency_1  \\\n",
       "toxcast CV       0.833       0.838       0.833       0.539         0.403   \n",
       "external set     0.778       0.812       0.751       0.501         0.450   \n",
       "\n",
       "              efficiency_0  accuracy  accuracy_1  accuracy_0  \n",
       "toxcast CV           0.559     0.867       0.760       0.878  \n",
       "external set         0.542     0.746       0.847       0.679  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Data overview\n",
    "# ToxCast\n",
    "total, neg, pos = calculate_set_sizes(train_dataframe, endpoint_toxcast)\n",
    "print(f'ToxCast data: {total} total, {neg} inactives, {pos} actives\\n')\n",
    "# External\n",
    "total, neg, pos = calculate_set_sizes(external_df, endpoint_external)\n",
    "print(f'External data: {total} total, {neg} inactives, {pos} actives\\n')\n",
    "\n",
    "# For three model set-ups do\n",
    "for knowtox_model, toxcast_X, fingerprint in zip(['original', 'normalised', 'normalised_balanced'], \n",
    "                                         [X_MorganMACCS, X_mmpcReduced, X_mmpcReduced], \n",
    "                                         [fp_MorganMACCS, fp_mmpcReduced, fp_mmpcReduced]):\n",
    "    # ToxCast\n",
    "    # Train model on ToxCast data and predict p-values on training data (cross-validation)\n",
    "    acps_cv_model = train_acp_cv(knowtox_model, toxcast_X, toxcast_y, toxcast_casn, toxcast_smiles,\n",
    "                                 cv, endpoint_toxcast, fingerprint)\n",
    "    # Load output dataframe with p-values\n",
    "    toxcast_filename = f'{crossvalidation_output_file}_{endpoint_toxcast}_{fingerprint}_{knowtox_model}.csv'\n",
    "    results_df_toxcast_cv = pd.read_csv(toxcast_filename)\n",
    "    \n",
    "    # External\n",
    "    # Predict and calculate p-values for external data set\n",
    "    model_predict_dataframe, model_fingerprint_dict, model_prediction_dict = \\\n",
    "        predict_acp_get_pvalues(acps_cv_model, external_df, fingerprint, endpoint_external)\n",
    "   \n",
    "    # Evaluate model internal (CV) and external data\n",
    "    evaluation_dict = {'validity': [], 'validity_1': [], 'validity_0': [], 'efficiency': [],\n",
    "                       'efficiency_1': [], 'efficiency_0': [], 'accuracy': [],\n",
    "                       'accuracy_1': [], 'accuracy_0': []}\n",
    "    \n",
    "    for dataframe, endpoint in zip([results_df_toxcast_cv, model_predict_dataframe],\n",
    "                                   [endpoint_toxcast, endpoint_external]):\n",
    "        validity_dict = calculate_validity(dataframe, endpoint, significance_level)\n",
    "        efficiency_dict = calculate_efficiency(dataframe, endpoint, significance_level)\n",
    "        accuracy_dict = calculate_accuracy(dataframe, endpoint, significance_level)\n",
    "        \n",
    "        for d in [validity_dict, efficiency_dict, accuracy_dict]:\n",
    "            for k, v in d.items():\n",
    "                evaluation_dict[k].append(v)\n",
    "         \n",
    "    evaluation_dataframe = pd.DataFrame(data=evaluation_dict, index = ['toxcast CV', 'external set'])\n",
    "    display(evaluation_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- From the original to the normalised model, the validity could be increased while efficiency dropped. \n",
    "- From the normalised to the normalised+balanced model, efficiency could be increased again. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
